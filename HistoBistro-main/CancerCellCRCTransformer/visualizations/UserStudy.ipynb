{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Study for multi-cohort MSI in CRC transformer paper\n",
    "\n",
    "The notebook evaluates the results of the pathologist evaluation of high attention patches of the multi-cohort model in the paper.\n",
    "\n",
    "Data properties:\n",
    "* 40 patients from the YCR-BCIP cohort\n",
    "* 20 patients with MSI-H ground truth, 20 patients with MSS ground truth\n",
    "* for each group 10 patients with the lowest classification scores and 10 patients with the highest classification scores were selected\n",
    "* 4 patches of the top100 highest scored attention patches per patient\n",
    "* 2 with the highest classification scores, 2 with the lowest classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to excel file with expert evaluations\n",
    "path = Path('evaluations_user_study.xlsx')\n",
    "df = pd.read_excel(path, sheet_name='evaluation_expert1')\n",
    "df2 = pd.read_excel(path, sheet_name='evaluation_expert2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge every 5 rows per patient to one row per patient\n",
    "categories = []\n",
    "for i in range(4):\n",
    "    categories.extend(list(df[f'tile {i}'].dropna().unique()))\n",
    "    categories.extend(list(df2[f'tile {i}'].dropna().unique()))\n",
    "categories = list(set(categories))\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore categories with max 2 occurences\n",
    "categories.pop(categories.index('goblet cells'))\n",
    "categories.pop(categories.index('signet ring cells'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with classification scores of the model's predictions\n",
    "scores = pd.read_excel(path, sheet_name='selected patients_10_low_high')\n",
    "df = pd.merge(df, scores, on='FILENAME')\n",
    "df2 = pd.merge(df2, scores, on='FILENAME')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the frequency of patterns for the different cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# tile 0 and 1 with high classification scores\n",
    "eval_df, eval_df2 = {}, {}\n",
    "for c in categories:\n",
    "    eval_df[c] = [0] * 4\n",
    "    eval_df2[c] = [0] * 4\n",
    "for gt in range(2):\n",
    "    for hl in range(2):\n",
    "        for tile in range(2):\n",
    "            counts = df[df['ground_truth'] == gt][df['high_low'] == hl][f'tile {tile}'].value_counts()\n",
    "            counts2 = df2[df2['ground_truth'] == gt][df2['high_low'] == hl][f'tile {tile}'].value_counts()\n",
    "\n",
    "            for c in counts.keys():\n",
    "                try:\n",
    "                    eval_df[c][2 * gt + hl] += counts[c]\n",
    "                except KeyError:\n",
    "                    continue            \n",
    "            for c in counts2.keys():\n",
    "                try:\n",
    "                    eval_df2[c][2 * gt + hl] += counts2[c]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "eval_df = pd.DataFrame(eval_df, index=['TN', 'FP', 'FN', 'TP']).T\n",
    "eval_df2 = pd.DataFrame(eval_df2, index=['TN', 'FP', 'FN', 'TP']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df, eval_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# tile 0 and 1 with high classification scores\n",
    "eval_df, eval_df2 = {}, {}\n",
    "for c in categories:\n",
    "    eval_df[c] = [0] * 4\n",
    "    eval_df2[c] = [0] * 4\n",
    "for gt in range(2):\n",
    "    for hl in range(2):\n",
    "        for tile in range(2):\n",
    "            try:\n",
    "                counts = df[df['ground_truth'] == gt][df['high_low'] == hl][f'tile {tile + 2}'].value_counts()\n",
    "            except KeyError:\n",
    "                continue\n",
    "            try:\n",
    "                counts2 = df2[df2['ground_truth'] == gt][df2['high_low'] == hl][f'tile {tile + 2}'].value_counts()\n",
    "            except KeyError:\n",
    "                continue\n",
    "            for c in counts.keys():\n",
    "                try:\n",
    "                    eval_df[c][2 * gt + hl] += counts[c]\n",
    "                except KeyError:\n",
    "                    continue            \n",
    "            for c in counts2.keys():\n",
    "                try:\n",
    "                    eval_df2[c][2 * gt + hl] += counts2[c]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "eval_df = pd.DataFrame(eval_df, index=['TN', 'FP', 'FN', 'TP']).T\n",
    "eval_df2 = pd.DataFrame(eval_df2, index=['TN', 'FP', 'FN', 'TP']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df, eval_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# tile 0 and 1 with high classification scores\n",
    "eval_df, eval_df2 = {}, {}\n",
    "for c in categories:\n",
    "    eval_df[c] = [0] * 4\n",
    "    eval_df2[c] = [0] * 4\n",
    "for gt in range(2):\n",
    "    for hl in range(2):\n",
    "        for tile in range(4):\n",
    "            try:\n",
    "                counts = df[df['ground_truth'] == gt][df['high_low'] == hl][f'tile {tile}'].value_counts()\n",
    "            except KeyError:\n",
    "                continue\n",
    "            try:\n",
    "                counts2 = df2[df2['ground_truth'] == gt][df2['high_low'] == hl][f'tile {tile}'].value_counts()\n",
    "            except KeyError:\n",
    "                continue\n",
    "            for c in counts.keys():\n",
    "                try:\n",
    "                    eval_df[c][2 * gt + hl] += counts[c]\n",
    "                except KeyError:\n",
    "                    continue            \n",
    "            for c in counts2.keys():\n",
    "                try:\n",
    "                    eval_df2[c][2 * gt + hl] += counts2[c]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "eval_df = pd.DataFrame(eval_df, index=['TN', 'FP', 'FN', 'TP']).T\n",
    "eval_df2 = pd.DataFrame(eval_df2, index=['TN', 'FP', 'FN', 'TP']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df, eval_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# all tiles with high attention scores\n",
    "eval_df, eval_df2 = {}, {}\n",
    "for c in categories:\n",
    "    eval_df[c] = [0] * 2\n",
    "    eval_df2[c] = [0] * 2\n",
    "for tile in range(4):\n",
    "    counts = df[f'tile {tile}'].value_counts()\n",
    "    counts2 = df2[f'tile {tile}'].value_counts()\n",
    "    for c in counts.keys():\n",
    "        try:\n",
    "            eval_df[c][tile // 2] += counts[c]\n",
    "        except KeyError:\n",
    "            pass    \n",
    "    for c in counts2.keys():\n",
    "        try:\n",
    "            eval_df2[c][tile // 2] += counts2[c]\n",
    "        except KeyError:\n",
    "            pass\n",
    "eval_df = pd.DataFrame(eval_df, index=['high', 'low']).T\n",
    "eval_df2 = pd.DataFrame(eval_df2, index=['high', 'low']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df, eval_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for hl in ['high', 'low']:\n",
    "    results[hl] = {\n",
    "        'mean': np.mean([eval_df[hl].values, eval_df2[hl].values], axis=0),\n",
    "        'std': np.std([eval_df[hl].values, eval_df2[hl].values], axis=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate statistisc whether patches with high and low classification scores follow the same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table from the two columns\n",
    "observed = np.array([results['high']['mean'], results['low']['mean']])\n",
    "\n",
    "# Calculate chi-square test and obtain the p-value\n",
    "chi2, p_value, _, _ = chi2_contingency(observed)\n",
    "\n",
    "print(\"Chi-squared statistic:\", chi2)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the frequency per tissue category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df.sort_values(by=['high'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = results['high']['mean'].argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'high'\n",
    "n = len(results[case]['mean'])\n",
    "fig, ax = plt.subplots(figsize=(16, 2))\n",
    "bars = ax.bar(np.arange(n), results[case]['mean'][ind] / 80, yerr=results[case]['std'][ind] / 80, width=0.6, color=colors)\n",
    "labels = [f\"{(results[case]['mean'][ind][i] / 80):.2f}\" for i in range(n)]\n",
    "ax.bar_label(bars, labels=labels, label_type='edge')\n",
    "plt.axis('off')\n",
    "# plt.savefig(figure_path / f'bar_{case}_error_bars.svg',  format='svg', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'low'\n",
    "n = len(results[case]['mean'])\n",
    "fig, ax = plt.subplots(figsize=(16, 2))\n",
    "bars = ax.bar(np.arange(n), -results[case]['mean'][ind] / 80, yerr=results[case]['std'][ind] / 80, width=0.6, color=colors)\n",
    "labels = [f\"{(results[case]['mean'][ind][i] / 80):.2f}\" for i in range(n)]\n",
    "ax.bar_label(bars, labels=labels, label_type='edge')\n",
    "plt.axis('off')\n",
    "# plt.savefig(figure_path / f'bar_{case}_error_bars.svg',  format='svg', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    print(f'{i}, {categories[ind[i]]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idkidc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
